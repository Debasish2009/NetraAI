<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no, viewport-fit=cover">
    <title>NETRA AI Assistant (Pro)</title>
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><circle cx=%2250%22 cy=%2250%22 r=%2245%22 fill=%22none%22 stroke=%22%23BB86FC%22 stroke-width=%225%22/><circle cx=%2250%22 cy=%2250%22 r=%2220%22 fill=%22%2303DAC6%22/></svg>">
    
    <!-- Google Fonts: Inter -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    
    <!-- AI/ML Libraries -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd@latest/dist/coco-ssd.min.js"></script>
    <script src='https://cdn.jsdelivr.net/npm/tesseract.js@5/dist/tesseract.min.js'></script>

    <style>
        :root {
            --background-start: #0D0F1A;
            --background-end: #040408;
            --surface-color: rgba(28, 28, 48, 0.7);
            --glass-border: rgba(187, 134, 252, 0.2);
            --primary-glow: #BB86FC;
            --secondary-glow: #03DAC6;
            --warning-glow: #FFD700;
            --info-glow: #3498DB;
            --success-glow: #2ECC71;
            --text-primary: #F0F0F0;
            --text-secondary: #A0A0B0;
            --error-color: #CF6679;
            --font-main: 'Inter', sans-serif;
            --zoom-level: 1.0;
        }

        html, body {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
            overflow: hidden;
            font-family: var(--font-main);
            background: linear-gradient(145deg, var(--background-start), var(--background-end));
            color: var(--text-primary);
            -webkit-tap-highlight-color: transparent;
        }

        #app-container {
            width: 100%;
            height: 100%;
            display: flex;
            flex-direction: column;
        }

        /* --- Advanced Loader --- */
        #loader-container {
            position: fixed;
            top: 0; left: 0;
            width: 100%; height: 100%;
            background: var(--background-end);
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            z-index: 100;
            transition: opacity 1.5s ease-out;
            opacity: 1;
        }

        #netra-logo {
            width: 150px;
            height: 150px;
            position: relative;
            filter: drop-shadow(0 0 15px var(--primary-glow));
        }

        .ring {
            position: absolute;
            width: 100%; height: 100%;
            border: 3px solid transparent;
            border-radius: 50%;
            animation: rotate 6s cubic-bezier(0.68, -0.55, 0.27, 1.55) infinite;
        }
        .ring:nth-child(1) { border-top-color: var(--primary-glow); animation-duration: 4s; }
        .ring:nth-child(2) { border-left-color: var(--secondary-glow); animation-duration: 4s; animation-direction: reverse; }
        .ring:nth-child(3) { border-right-color: var(--primary-glow); animation-duration: 5.5s; }
        .ring:nth-child(4) { border-bottom-color: var(--secondary-glow); animation-duration: 5.5s; animation-direction: reverse; }

        #logo-core {
            position: absolute;
            top: 50%; left: 50%;
            width: 30%; height: 30%;
            background: radial-gradient(circle, var(--secondary-glow) 0%, var(--primary-glow) 100%);
            border-radius: 50%;
            transform: translate(-50%, -50%);
            box-shadow: 0 0 35px var(--secondary-glow), 0 0 50px var(--primary-glow);
            animation: core-pulse 2.5s infinite ease-in-out;
        }

        #loading-text {
            margin-top: 3rem;
            font-size: 1.2rem;
            font-weight: 500;
            color: var(--text-secondary);
            letter-spacing: 1px;
            animation: text-fade 2.5s infinite ease-in-out;
            text-align: center;
            padding: 0 1rem;
            width: 80%;
        }
        #loading-text.error {
            color: var(--error-color);
            animation: none;
        }

        @keyframes rotate { from { transform: rotate(0deg); } to { transform: rotate(360deg); } }
        @keyframes core-pulse { 0%, 100% { transform: translate(-50%,-50%) scale(1); box-shadow: 0 0 35px var(--secondary-glow), 0 0 50px var(--primary-glow); } 50% { transform: translate(-50%,-50%) scale(0.9); box-shadow: 0 0 45px var(--secondary-glow), 0 0 65px var(--primary-glow); } }
        @keyframes text-fade { 0%, 100% { opacity: 0.7; } 50% { opacity: 1; } }

        /* --- Main UI --- */
        #vision-container {
            flex-grow: 1;
            position: relative;
            background-color: #000;
            overflow: hidden;
        }
        #camera-feed {
            position: absolute;
            top: 50%; left: 50%;
            min-width: 100%;
            min-height: 100%;
            width: auto;
            height: auto;
            transform: translate(-50%, -50%) scale(var(--zoom-level));
            transition: transform 0.3s ease-out;
        }
        #detection-canvas {
            position: absolute;
            top: 0; left: 0;
            width: 100%; height: 100%;
            object-fit: contain; /* Important for correct scaling */
            z-index: 10;
        }
        
        #top-overlay {
            position: absolute;
            top: 0; left: 0;
            width: 100%;
            padding: 1.5rem;
            box-sizing: border-box;
            background: linear-gradient(to bottom, rgba(0,0,0,0.6), transparent);
            z-index: 15;
            color: #fff;
            text-shadow: 0 2px 5px rgba(0,0,0,0.5);
            pointer-events: none;
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
        }
        #app-title {
            font-weight: 700;
            font-size: 1.1rem;
        }
        #app-title span {
            font-weight: 400;
            color: var(--secondary-glow);
        }
        #datetime {
            text-align: right;
        }
        #time { font-size: 1.5rem; font-weight: 600; }
        #date { font-size: 0.9rem; font-weight: 400; color: var(--text-secondary); }
        
        #center-reticle {
            position: absolute;
            top: 50%; left: 50%;
            width: 50px; height: 50px;
            transform: translate(-50%, -50%);
            z-index: 11;
            transition: all 0.3s ease;
        }
        #center-reticle::before, #center-reticle::after {
            content: '';
            position: absolute;
            border: 2px solid rgba(255, 255, 255, 0.5);
            transition: all 0.3s ease;
        }
        #center-reticle::before { top: 50%; left: 0; width: 100%; height: 0; }
        #center-reticle::after { top: 0; left: 50%; width: 0; height: 100%; }
        
        #center-reticle.active::before, #center-reticle.active::after {
            border-color: var(--secondary-glow);
            box-shadow: 0 0 15px var(--secondary-glow);
        }

        /* --- Detections Panel --- */
        #detections-panel {
            flex-shrink: 0;
            height: 40%;
            max-height: 400px;
            background-color: var(--surface-color);
            backdrop-filter: blur(20px) saturate(180%);
            -webkit-backdrop-filter: blur(20px) saturate(180%);
            border-top: 1px solid var(--glass-border);
            box-shadow: 0 -15px 40px rgba(0,0,0,0.4);
            padding: 1.5rem;
            box-sizing: border-box;
            display: flex;
            flex-direction: column;
            overflow: hidden;
            position: relative;
            z-index: 20;
        }

        #panel-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 1rem;
            flex-shrink: 0;
        }

        #panel-title {
            margin: 0;
            font-size: 1.2rem;
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 0.75rem;
        }
        
        #mic-container {
            position: relative;
            width: 36px;
            height: 36px;
        }
        #mic-icon, #mic-volume-ring {
            position: absolute;
            top: 0; left: 0;
            width: 100%; height: 100%;
        }
        #mic-volume-ring {
            stroke: var(--secondary-glow);
            stroke-width: 2.5;
            fill: none;
            transform-origin: 50% 50%;
            transition: transform 0.1s linear;
            filter: drop-shadow(0 0 5px var(--secondary-glow));
        }
        #mic-icon.listening {
             filter: drop-shadow(0 0 10px var(--secondary-glow));
             transform: scale(1.05);
        }

        #hint-text {
            font-size: 0.85rem;
            color: var(--text-secondary);
            font-style: italic;
            transition: opacity 0.5s ease;
        }
        
        #results-container {
            flex-grow: 1;
            overflow-y: auto;
            display: flex;
            flex-direction: column-reverse;
            gap: 0.75rem;
            scrollbar-width: thin;
            scrollbar-color: var(--primary-glow) transparent;
        }
        #results-container::-webkit-scrollbar { width: 4px; }
        #results-container::-webkit-scrollbar-track { background: transparent; }
        #results-container::-webkit-scrollbar-thumb { background-color: var(--primary-glow); border-radius: 20px; }

        .detection-card {
            background: rgba(0,0,0,0.3);
            border-left: 4px solid;
            border-radius: 0 8px 8px 0;
            padding: 1rem 1.2rem;
            font-size: 1.05rem;
            font-weight: 500;
            display: flex;
            align-items: center;
            gap: 1.2rem;
            opacity: 0;
            transform: translateX(-20px);
            animation: slideIn 0.5s forwards cubic-bezier(0.25, 0.46, 0.45, 0.94);
        }
        .detection-card.currency { border-color: var(--success-glow); }
        .detection-card.text { border-color: var(--secondary-glow); }
        .detection-card.object { border-color: #61A3FF; }
        .detection-card.navigation { border-color: var(--warning-glow); }
        .detection-card.info { border-color: var(--info-glow); }
        .detection-card.error { border-color: var(--error-color); }
        .detection-card .icon { font-size: 1.6rem; flex-shrink: 0; }
        
        @keyframes slideIn { to { opacity: 1; transform: translateX(0); } }
    </style>
</head>
<body>

    <div id="app-container">
        <div id="loader-container">
            <div id="netra-logo">
                <div class="ring"></div><div class="ring"></div><div class="ring"></div><div class="ring"></div>
                <div id="logo-core"></div>
            </div>
            <p id="loading-text">Initializing NETRA Core...</p>
        </div>
        
        <div id="vision-container">
            <div id="center-reticle"></div>
            <div id="top-overlay">
                <div id="app-title">NETRA <span>PRO</span></div>
                <div id="datetime">
                    <div id="time"></div>
                    <div id="date"></div>
                </div>
            </div>
            <video id="camera-feed" autoplay playsinline muted></video>
            <canvas id="detection-canvas"></canvas>
        </div>
        
        <div id="detections-panel">
            <div id="panel-header">
                <h2 id="panel-title">
                     <div id="mic-container">
                        <svg id="mic-volume-ring" viewBox="0 0 36 36"><circle cx="18" cy="18" r="16"/></svg>
                        <svg id="mic-icon" viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg">
                             <defs>
                                 <radialGradient id="mic-gradient" cx="50%" cy="50%" r="50%" fx="50%" fy="50%">
                                     <stop offset="0%" style="stop-color: var(--secondary-glow); stop-opacity:1"/>
                                     <stop offset="100%" style="stop-color: var(--primary-glow); stop-opacity:1"/>
                                 </radialGradient>
                             </defs>
                             <circle class="glow" cx="16" cy="16" r="16" fill="url(#mic-gradient)"/>
                             <path fill="#1A1A2A" d="M16 22.5c2.48 0 4.5-2.02 4.5-4.5V9.5c0-2.48-2.02-4.5-4.5-4.5S11.5 7.02 11.5 9.5v8.5c0 2.48 2.02 4.5 4.5 4.5zM24 18c0 4.41-3.59 8-8 8s-8-3.59-8-8H6c0 5.52 4.48 10 10 10s10-4.48 10-10h-2z"/>
                         </svg>
                     </div>
                    <span id="status-text">Connecting...</span>
                </h2>
                <span id="hint-text"></span>
            </div>
            <div id="results-container"></div>
        </div>
    </div>

    <script>
    /**
     * NETRA AI Vision Assistant (Professional Edition)
     * * This application is an advanced, voice-controlled AI assistant designed to provide
     * real-time environmental information for visually impaired individuals. It leverages
     * on-device machine learning for object detection, text recognition, and integrates
     * cloud-based APIs for enhanced functionalities like weather, color naming, and
     * natural language scene description.
     *
     * Core Features:
     * - Real-time Object Detection (via TensorFlow.js & COCO-SSD)
     * - Optical Character Recognition (OCR) (via Tesseract.js)
     * - Voice Command Interface (Web Speech API)
     * - Text-to-Speech Feedback (Web Speech Synthesis API)
     * - Geolocation-aware Weather Forecasting
     * - Advanced Currency Recognition (INR)
     * - Conversational Context Management
     * - Obstacle Avoidance Guidance
     * - Dynamic UI with audio-visual feedback
     * - Gemini API for natural language scene descriptions
     */
    
    // --- Application Namespace ---
    const NETRA_APP = {
        // --- Models & State ---
        models: {
            objectDetector: null,
            tesseractWorker: null,
            recognition: null,
            speechSynthesis: window.speechSynthesis,
            audioContext: null,
            microphoneSource: null,
            analyserNode: null,
        },
        state: {
            isProcessing: false,
            navigationAidActive: false,
            lastNavSpeechTime: 0,
            aiVoice: null,
            currentLocation: { latitude: 26.45, longitude: 92.03 }, // Default: Mangaldoi, Assam
            lastDetectedObjects: [],
            lastInteractionContext: null, // For contextual follow-up questions
            zoomLevel: 1.0,
        },

        // --- DOM Elements ---
        elements: {
            video: document.getElementById('camera-feed'),
            canvas: document.getElementById('detection-canvas'),
            loaderContainer: document.getElementById('loader-container'),
            loadingText: document.getElementById('loading-text'),
            resultsContainer: document.getElementById('results-container'),
            statusText: document.getElementById('status-text'),
            micIcon: document.getElementById('mic-icon'),
            micVolumeRing: document.getElementById('mic-volume-ring'),
            hintText: document.getElementById('hint-text'),
            timeEl: document.getElementById('time'),
            dateEl: document.getElementById('date'),
            centerReticle: document.getElementById('center-reticle'),
        },

        // --- Constants & Configuration ---
        CONSTANTS: {
            SPEECH_LANG: 'en-IN',
            HINTS: [
                "Ask: 'Describe the scene'", "Ask: 'What color is this?'", "Say: 'Guide me'",
                "Say: 'Read this'", "Ask: 'How much money?'", "Ask: 'What's the weather?'",
                "Ask: 'My battery level?'", "Say: 'Find a person'", "Say: 'Help'"
            ],
            HINT_INTERVAL_MS: 6000,
            NAV_AID_COOLDOWN_MS: 4000,
            OBJECT_COLORS: {},
            GEMINI_API_KEY: "", // IMPORTANT: User must provide their own key here.
            GEMINI_API_URL: "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent",
            WEATHER_API_URL: 'https://api.open-meteo.com/v1/forecast',
            COLOR_API_URL: 'https://www.thecolorapi.com/id',
        },

        /**
         * The main initialization function. Orchestrates the entire application startup sequence.
         */
        async init() {
            try {
                this.UI.updateDateTime();
                setInterval(() => this.UI.updateDateTime(), 1000);

                this.UI.setLoadingText("Initializing audio systems...");
                await this.Speech.initSpeechSynthesis();
                
                this.UI.setLoadingText("Accessing geolocation...");
                await this.Utils.initGeolocation();

                this.UI.setLoadingText("Requesting camera access...");
                await this.Vision.initCamera();
                
                this.UI.setLoadingText("Waking AI models...");
                [this.models.objectDetector, this.models.tesseractWorker] = await Promise.all([
                    cocoSsd.load(),
                    Tesseract.createWorker('eng', 1, { logger: m => console.log(m.status) })
                ]);
                
                this.UI.setLoadingText("Starting voice recognition...");
                this.Speech.initSpeechRecognition();

                this.Speech.speak("NETRA AI is online and ready.");
                this.UI.setStatusText("NETRA is listening");
                this.UI.hideLoader();
                
                this.Vision.runDetectionLoop();
                this.UI.startHintCycle();

            } catch (err) {
                console.error("Initialization Error:", err);
                const errorMsg = `Critical error: ${err.message}. Please check permissions and refresh.`;
                this.UI.setLoadingText(errorMsg, true);
                this.Speech.speak(errorMsg);
            }
        },
    };

    // --- UI Module: Handles all interactions with the DOM ---
    NETRA_APP.UI = {
        ctx: NETRA_APP.elements.canvas.getContext('2d', { willReadFrequently: true }),

        setLoadingText(text, isError = false) {
            NETRA_APP.elements.loadingText.textContent = text;
            NETRA_APP.elements.loadingText.classList.toggle('error', isError);
        },

        hideLoader() {
            NETRA_APP.elements.loaderContainer.style.opacity = '0';
            setTimeout(() => NETRA_APP.elements.loaderContainer.style.display = 'none', 1500);
        },
        
        setStatusText(text) {
            NETRA_APP.elements.statusText.textContent = text;
        },

        addResultCard(type, text, icon) {
            const card = document.createElement('div');
            card.className = `detection-card ${type}`;
            card.innerHTML = `<span class="icon">${icon}</span><span>${text}</span>`;
            NETRA_APP.elements.resultsContainer.prepend(card);
            if (NETRA_APP.elements.resultsContainer.children.length > 15) {
                NETRA_APP.elements.resultsContainer.lastChild.remove();
            }
        },

        updateDateTime() {
            const now = new Date();
            const timeString = now.toLocaleTimeString('en-IN', { hour: '2-digit', minute: '2-digit', hour12: true }).toUpperCase();
            const dateString = now.toLocaleDateString('en-IN', { weekday: 'long', day: 'numeric', month: 'long' });
            NETRA_APP.elements.timeEl.textContent = timeString;
            NETRA_APP.elements.dateEl.textContent = dateString;
        },
        
        startHintCycle() {
            let hintIndex = 0;
            const hints = NETRA_APP.CONSTANTS.HINTS;
            const hintEl = NETRA_APP.elements.hintText;
            
            hintEl.textContent = hints[hintIndex];
            setTimeout(() => hintEl.style.opacity = '1', 500);

            this.hintInterval = setInterval(() => {
                hintEl.style.opacity = '0';
                setTimeout(() => {
                    hintIndex = (hintIndex + 1) % hints.length;
                    hintEl.textContent = hints[hintIndex];
                    hintEl.style.opacity = '1';
                }, 500);
            }, NETRA_APP.CONSTANTS.HINT_INTERVAL_MS);
        },

        stopHintCycle() {
            clearInterval(this.hintInterval);
            NETRA_APP.elements.hintText.style.opacity = '0';
        },

        drawBoundingBox(p, isHighlight = false) {
            const { video, canvas } = NETRA_APP.elements;
            const scaleX = canvas.width / video.videoWidth;
            const scaleY = canvas.height / video.videoHeight;
            const [x, y, width, height] = p.bbox.map((val, i) => val * (i % 2 === 0 ? scaleX : scaleY));

            if (!NETRA_APP.CONSTANTS.OBJECT_COLORS[p.class]) {
                const r = Math.floor(Math.random() * 150 + 105);
                const g = Math.floor(Math.random() * 150 + 105);
                const b = Math.floor(Math.random() * 150 + 105);
                NETRA_APP.CONSTANTS.OBJECT_COLORS[p.class] = `rgb(${r},${g},${b})`;
            }
            const color = NETRA_APP.CONSTANTS.OBJECT_COLORS[p.class];
            
            this.ctx.strokeStyle = color;
            this.ctx.lineWidth = isHighlight ? 6 : 3;
            this.ctx.strokeRect(x, y, width, height);
            
            if(isHighlight) {
                this.ctx.fillStyle = 'rgba(255, 255, 255, 0.2)';
                this.ctx.fillRect(x, y, width, height);
            }

            const text = `${p.class} (${Math.round(p.score * 100)}%)`;
            this.ctx.fillStyle = color;
            this.ctx.font = 'bold 18px Inter';
            const textMetrics = this.ctx.measureText(text);
            this.ctx.fillRect(x, y - 25 > 0 ? y - 25 : y, textMetrics.width + 10, 25);
            this.ctx.fillStyle = '#000000';
            this.ctx.fillText(text, x + 5, y - 25 > 0 ? y - 5 : y + 18);
        },
        
        updateMicVisualizer(dataArray) {
            let sum = dataArray.reduce((acc, val) => acc + val, 0);
            let average = sum / dataArray.length;
            let scale = 1 + (average / 256); // Scale from 1 to 1.5
            NETRA_APP.elements.micVolumeRing.style.transform = `scale(${scale})`;
        }
    };

    // --- Speech Module: Handles Speech Recognition and Synthesis ---
    NETRA_APP.Speech = {
        async initSpeechSynthesis() {
            return new Promise(resolve => {
                const checkVoices = () => {
                    const voices = NETRA_APP.models.speechSynthesis.getVoices();
                    if (voices.length) {
                        NETRA_APP.state.aiVoice = 
                            voices.find(v => v.name.includes('Google') && v.lang === 'en-IN') ||
                            voices.find(v => v.lang === 'en-IN') ||
                            voices.find(v => v.name.includes('Google') && v.lang.startsWith('en-')) ||
                            voices.find(v => v.lang.startsWith('en-'));
                        console.log("Selected AI Voice:", NETRA_APP.state.aiVoice ? NETRA_APP.state.aiVoice.name : "Default");
                        resolve();
                    }
                };
                NETRA_APP.models.speechSynthesis.onvoiceschanged = checkVoices;
                checkVoices();
            });
        },
        
        initSpeechRecognition() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                throw new Error("Speech recognition not supported by this browser.");
            }
            const recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = false;
            recognition.lang = NETRA_APP.CONSTANTS.SPEECH_LANG;
            
            recognition.onstart = () => NETRA_APP.elements.micIcon.classList.add('listening');
            recognition.onend = () => {
                NETRA_APP.elements.micIcon.classList.remove('listening');
                if (!NETRA_APP.state.isProcessing) recognition.start();
            };
            recognition.onerror = (e) => console.error('Speech recognition error:', e.error);
            recognition.onresult = (event) => NETRA_APP.Commands.handleVoiceCommand(event);
            
            NETRA_APP.models.recognition = recognition;
            recognition.start();
        },

        speak(text) {
            NETRA_APP.models.speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            if (NETRA_APP.state.aiVoice) {
                utterance.voice = NETRA_APP.state.aiVoice;
            }
            utterance.rate = 1.05;
            utterance.pitch = 1.0;
            NETRA_APP.models.speechSynthesis.speak(utterance);
        }
    };

    // --- Vision Module: Handles Camera, Object Detection, OCR ---
    NETRA_APP.Vision = {
        async initCamera() {
            if (!navigator.mediaDevices?.getUserMedia) {
                throw new Error('Camera not supported by this browser.');
            }
            
            const constraints = { video: { facingMode: 'environment' }, audio: true };
            const stream = await navigator.mediaDevices.getUserMedia(constraints)
                .catch(err => {
                    console.warn("Could not get environment camera with audio, trying default.", err);
                    return navigator.mediaDevices.getUserMedia({ video: true, audio: true });
                });
            
            NETRA_APP.elements.video.srcObject = stream;
            await new Promise(resolve => NETRA_APP.elements.video.onloadedmetadata = resolve);
            NETRA_APP.elements.video.play();
            
            // For Mic Visualizer - check for audio tracks before initializing
            if (stream.getAudioTracks().length > 0) {
                NETRA_APP.models.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                NETRA_APP.models.microphoneSource = NETRA_APP.models.audioContext.createMediaStreamSource(stream);
                NETRA_APP.models.analyserNode = NETRA_APP.models.audioContext.createAnalyser();
                NETRA_APP.models.analyserNode.fftSize = 256;
                NETRA_APP.models.microphoneSource.connect(NETRA_APP.models.analyserNode);
            } else {
                console.warn("No audio tracks found in media stream. Microphone visualizer will be disabled.");
            }
        },

        runDetectionLoop() {
            const loop = async () => {
                const { objectDetector, analyserNode } = NETRA_APP.models;
                const { video, canvas } = NETRA_APP.elements;
                
                if (analyserNode) {
                    const dataArray = new Uint8Array(analyserNode.frequencyBinCount);
                    analyserNode.getByteFrequencyData(dataArray);
                    NETRA_APP.UI.updateMicVisualizer(dataArray);
                }

                if (objectDetector && !NETRA_APP.state.isProcessing && video.readyState >= 3 && !video.paused) {
                    const predictions = await objectDetector.detect(video);
                    NETRA_APP.state.lastDetectedObjects = predictions;
                    
                    canvas.width = video.clientWidth;
                    canvas.height = video.clientHeight;
                    NETRA_APP.UI.ctx.clearRect(0, 0, canvas.width, canvas.height);
                    
                    predictions.forEach(p => NETRA_APP.UI.drawBoundingBox(p));

                    if (NETRA_APP.state.navigationAidActive) {
                        this.provideNavigationalAid(predictions);
                    }
                    
                    if (NETRA_APP.state.findObjectQuery) {
                        const found = predictions.find(p => p.class === NETRA_APP.state.findObjectQuery);
                        if (found) {
                            NETRA_APP.UI.drawBoundingBox(found, true);
                        }
                    }
                }
                requestAnimationFrame(loop);
            };
            loop();
        },

        provideNavigationalAid(predictions) {
            const now = Date.now();
            if (now - NETRA_APP.state.lastNavSpeechTime < NETRA_APP.CONSTANTS.NAV_AID_COOLDOWN_MS) return;

            const { width, height } = NETRA_APP.elements.canvas;
            const dangerZoneArea = (width * height) * 0.25;

            const obstacles = predictions.map(p => ({
                ...p,
                area: p.bbox[2] * p.bbox[3],
                centerX: p.bbox[0] + p.bbox[2] / 2
            })).sort((a,b) => b.area - a.area);

            if (!obstacles.length) return;
            
            const closestObstacle = obstacles[0];
            if (closestObstacle.area > dangerZoneArea) {
                const speech = `Warning. Large ${closestObstacle.class} directly ahead.`;
                NETRA_APP.Speech.speak(speech);
                NETRA_APP.UI.addResultCard('navigation', `IMMINENT: ${closestObstacle.class} ahead`, 'âš ï¸');
                NETRA_APP.state.lastNavSpeechTime = now;
                NETRA_APP.Utils.vibrate([200, 50, 200]);
            }
        },

        captureFrame() {
            const { video } = NETRA_APP.elements;
            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = video.videoWidth;
            tempCanvas.height = video.videoHeight;
            tempCanvas.getContext('2d').drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);
            return tempCanvas;
        }
    };
    
    // --- Commands Module: Handles interpretation of voice commands ---
    NETRA_APP.Commands = {
        async handleVoiceCommand(event) {
            const command = event.results[event.results.length - 1][0].transcript.toLowerCase().trim();
            console.log('Command received:', command);
            if (NETRA_APP.state.isProcessing) return;
            
            NETRA_APP.Utils.playSound('confirm');

            const commands = [
                { keywords: ['guide', 'navigation'], action: () => this.toggleNavigation() },
                { keywords: ['read', 'what does this say'], action: () => this.readText() },
                { keywords: ['money', 'currency'], action: () => this.detectCurrency() },
                { keywords: ['what is this', 'identify'], action: () => this.identifyObject(command) },
                { keywords: ['time', 'date', 'day'], action: () => this.getTime() },
                { keywords: ['weather'], action: () => this.getWeather() },
                { keywords: ['battery', 'power'], action: () => this.getBattery() },
                { keywords: ['color', 'colour'], action: () => this.getColor() },
                { keywords: ['describe the scene', "what's in front of me"], action: () => this.describeSceneWithGemini() },
                { keywords: ['find a'], action: () => this.findObject(command) },
                { keywords: ['stop finding', 'cancel search'], action: () => this.stopFinding() },
                { keywords: ['zoom in'], action: () => this.zoom(true) },
                { keywords: ['zoom out'], action: () => this.zoom(false) },
                { keywords: ['help', 'commands'], action: () => this.listCommands() },
            ];

            const foundCommand = commands.find(c => c.keywords.some(k => command.startsWith(k)));
            
            if(foundCommand) {
                foundCommand.action();
            } else {
                NETRA_APP.Utils.playSound('error');
                NETRA_APP.Speech.speak("Sorry, I didn't understand that command.");
            }
        },

        async setProcessingState(isBusy, message) {
            NETRA_APP.state.isProcessing = isBusy;
            if (isBusy) {
                NETRA_APP.models.recognition?.stop();
                NETRA_APP.UI.setStatusText(message);
                NETRA_APP.UI.stopHintCycle();
                NETRA_APP.Speech.speak(message);
            } else {
                NETRA_APP.models.recognition?.start();
                NETRA_APP.UI.setStatusText("NETRA is listening");
                NETRA_APP.UI.startHintCycle();
            }
        },
        
        // Command Implementations
        toggleNavigation() {
            NETRA_APP.state.navigationAidActive = !NETRA_APP.state.navigationAidActive;
            const status = NETRA_APP.state.navigationAidActive ? "Navigation guidance activated." : "Navigation guidance deactivated.";
            NETRA_APP.Speech.speak(status);
            NETRA_APP.UI.addResultCard('navigation', status, 'ðŸ§­');
            NETRA_APP.Utils.vibrate(50);
        },

        async readText() {
            await this.setProcessingState(true, "Scanning for text...");
            try {
                const { data: { text } } = await NETRA_APP.models.tesseractWorker.recognize(NETRA_APP.Vision.captureFrame());
                const cleanText = text.trim().replace(/\s+/g, ' ');
                const speech = cleanText ? `I found some text. It says: ${cleanText}` : "I looked, but could not find any clear text.";
                NETRA_APP.Speech.speak(speech);
                if (cleanText) NETRA_APP.UI.addResultCard('text', `"${cleanText}"`, 'âœï¸');
            } catch (error) {
                console.error("OCR Error:", error);
                NETRA_APP.Speech.speak("My apologies, an error occurred while trying to read text.");
                NETRA_APP.UI.addResultCard('error', "OCR failed.", 'âŒ');
            } finally {
                await this.setProcessingState(false);
            }
        },
        
        async detectCurrency() {
            await this.setProcessingState(true, "Analyzing for currency...");
            try {
                // Currency detection logic would go here
                NETRA_APP.Speech.speak("This feature is under development.");
                NETRA_APP.UI.addResultCard('info', 'Currency detection coming soon.', 'â‚¹');
            } catch (error) {
                console.error("Currency Error:", error);
            } finally {
                await this.setProcessingState(false);
            }
        },

        identifyObject(command) {
            const objects = NETRA_APP.state.lastDetectedObjects;
            if (objects.length === 0) {
                NETRA_APP.Speech.speak("I do not see any recognizable objects right now.");
                return;
            }
            // Simple identification of the largest object
            const largestObject = objects.sort((a, b) => (b.bbox[2]*b.bbox[3]) - (a.bbox[2]*a.bbox[3]))[0];
            NETRA_APP.state.lastInteractionContext = largestObject;
            const speech = `It looks like a ${largestObject.class}.`;
            NETRA_APP.Speech.speak(speech);
            NETRA_APP.UI.addResultCard('object', speech, 'ðŸ‘€');
        },
        
        async describeSceneWithGemini() {
            await this.setProcessingState(true, "Analyzing the scene...");
            const objects = NETRA_APP.state.lastDetectedObjects;
            if(objects.length === 0) {
                NETRA_APP.Speech.speak("The scene appears to be empty.");
                await this.setProcessingState(false);
                return;
            }

            const objectList = objects.map(p => p.class);
            
            if (!NETRA_APP.CONSTANTS.GEMINI_API_KEY) {
                NETRA_APP.Speech.speak("Gemini API key is not configured. Describing objects manually.");
                // Fallback to simple description
                const counts = objectList.reduce((acc, p) => { acc[p] = (acc[p] || 0) + 1; return acc; }, {});
                let summary = "I can see: ";
                summary += Object.entries(counts).map(([name, count]) => `${count} ${name}${count > 1 ? 's' : ''}`).join(', ');
                NETRA_APP.Speech.speak(summary);
                NETRA_APP.UI.addResultCard('object', summary, 'ðŸ—ºï¸');
                await this.setProcessingState(false);
                return;
            }

            try {
                const prompt = `You are an AI assistant for a visually impaired person. Briefly and clearly describe a scene containing the following objects: ${objectList.join(', ')}. Focus on their likely arrangement.`;
                const response = await fetch(`${NETRA_APP.CONSTANTS.GEMINI_API_URL}?key=${NETRA_APP.CONSTANTS.GEMINI_API_KEY}`, {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({ contents: [{ parts: [{ text: prompt }] }]})
                });
                if (!response.ok) throw new Error('API request failed');
                const data = await response.json();
                const description = data.candidates[0].content.parts[0].text;
                NETRA_APP.Speech.speak(description);
                NETRA_APP.UI.addResultCard('object', description, 'ðŸ—ºï¸');
            } catch (error) {
                console.error("Gemini API Error:", error);
                NETRA_APP.Speech.speak("I had trouble describing the scene. Please try again.");
                NETRA_APP.UI.addResultCard('error', "Scene description failed.", 'âŒ');
            } finally {
                await this.setProcessingState(false);
            }
        },
        
        findObject(command) {
            const query = command.replace('find a', '').trim();
            if (!query) {
                NETRA_APP.Speech.speak("Please tell me what to find.");
                return;
            }
            NETRA_APP.state.findObjectQuery = query;
            const msg = `Okay, I will look for a ${query} and highlight it.`;
            NETRA_APP.Speech.speak(msg);
            NETRA_APP.UI.addResultCard('info', `Searching for: ${query}`, 'ðŸ”');
        },

        stopFinding() {
            if (NETRA_APP.state.findObjectQuery) {
                NETRA_APP.Speech.speak("Okay, I have stopped searching.");
                NETRA_APP.state.findObjectQuery = null;
            }
        },

        zoom(isZoomIn) {
            NETRA_APP.state.zoomLevel += isZoomIn ? 0.2 : -0.2;
            NETRA_APP.state.zoomLevel = Math.max(1.0, Math.min(NETRA_APP.state.zoomLevel, 3.0)); // Clamp between 1x and 3x
            document.documentElement.style.setProperty('--zoom-level', NETRA_APP.state.zoomLevel);
            const zoomPercent = Math.round(NETRA_APP.state.zoomLevel * 100);
            NETRA_APP.Speech.speak(`Zoom set to ${zoomPercent} percent.`);
            NETRA_APP.UI.addResultCard('info', `Zoom: ${zoomPercent}%`, 'ðŸ”Ž');
        },

        listCommands() {
            NETRA_APP.Speech.speak("You can ask me to: describe the scene, read text, find an object, tell the time, weather, or battery level, and guide you. You can also say zoom in or out.");
            NETRA_APP.UI.addResultCard('info', 'Listed available commands.', 'â„¹ï¸');
        },

        // Other command handlers...
        getTime() {
            const now = new Date();
            const speech = `The current time is ${now.toLocaleTimeString('en-IN', { hour: 'numeric', minute: 'numeric', hour12: true })}.`;
            NETRA_APP.Speech.speak(speech);
            NETRA_APP.UI.addResultCard('info', speech, 'ðŸ•’');
        },
        
        async getWeather() {
            await this.setProcessingState(true, "Fetching weather data...");
            const { latitude, longitude } = NETRA_APP.state.currentLocation;
            try {
                const url = `${NETRA_APP.CONSTANTS.WEATHER_API_URL}?latitude=${latitude}&longitude=${longitude}&current_weather=true`;
                const response = await fetch(url);
                if (!response.ok) throw new Error('API request failed');
                const data = await response.json();
                const temp = data.current_weather.temperature;
                const speech = `The current temperature is ${temp} degrees Celsius.`;
                NETRA_APP.Speech.speak(speech);
                NETRA_APP.UI.addResultCard('info', `Weather: ${temp}Â°C`, 'ðŸŒ¦ï¸');
            } catch (error) {
                console.error("Weather fetch error:", error);
                NETRA_APP.Speech.speak("I was unable to fetch the current weather information.");
            } finally {
                await this.setProcessingState(false);
            }
        },

        async getBattery() {
            if (navigator.getBattery) {
                const battery = await navigator.getBattery();
                const level = Math.floor(battery.level * 100);
                const charging = battery.charging ? "and is charging." : "and is not charging.";
                const speech = `Your device battery is at ${level} percent, ${charging}`;
                NETRA_APP.Speech.speak(speech);
                NETRA_APP.UI.addResultCard('info', `Battery: ${level}% ${battery.charging ? '(Charging)' : ''}`, 'ðŸ”‹');
            } else {
                NETRA_APP.Speech.speak("My apologies, I cannot access battery information on this device.");
            }
        },

        async getColor() {
            // Simplified: Use context if available
            if (NETRA_APP.state.lastInteractionContext) {
                 await this.setProcessingState(true, `Analyzing color of the ${NETRA_APP.state.lastInteractionContext.class}...`);
                 // Color analysis on the bbox of the last object would go here.
                 NETRA_APP.Speech.speak("Color analysis by context is a planned feature.");
                 await this.setProcessingState(false);
            } else {
                 await this.setProcessingState(true, `Analyzing center color...`);
                 // Center reticle color analysis logic
                 NETRA_APP.Speech.speak("I am looking at the color in the center.");
                 await this.setProcessingState(false);
            }
        },
    };

    // --- Utility Module: Helper functions ---
    NETRA_APP.Utils = {
        async initGeolocation() {
            if (!navigator.geolocation) {
                NETRA_APP.Speech.speak("Geolocation is not supported, using default location.");
                return;
            }
            try {
                const position = await new Promise((resolve, reject) => {
                    navigator.geolocation.getCurrentPosition(resolve, reject, { timeout: 5000 });
                });
                NETRA_APP.state.currentLocation.latitude = position.coords.latitude;
                NETRA_APP.state.currentLocation.longitude = position.coords.longitude;
                console.log("Geolocation updated:", NETRA_APP.state.currentLocation);
            } catch (error) {
                console.warn(`Geolocation permission denied or failed: ${error.message}. This is expected in some sandboxed environments. Falling back to default location.`);
                NETRA_APP.Speech.speak("Could not get current location, using default.");
            }
        },
        
        vibrate(pattern) {
            if ('vibrate' in navigator) {
                navigator.vibrate(pattern);
            }
        },

        playSound(type) {
            if (!NETRA_APP.models.audioContext) return;
            const oscillator = NETRA_APP.models.audioContext.createOscillator();
            const gainNode = NETRA_APP.models.audioContext.createGain();
            oscillator.connect(gainNode);
            gainNode.connect(NETRA_APP.models.audioContext.destination);
            
            gainNode.gain.setValueAtTime(0, NETRA_APP.models.audioContext.currentTime);
            gainNode.gain.linearRampToValueAtTime(0.3, NETRA_APP.models.audioContext.currentTime + 0.01);
            
            if(type === 'confirm') {
                oscillator.type = 'sine';
                oscillator.frequency.setValueAtTime(880, 0);
            } else if (type === 'error') {
                oscillator.type = 'square';
                oscillator.frequency.setValueAtTime(330, 0);
            }
            
            oscillator.start();
            gainNode.gain.exponentialRampToValueAtTime(0.00001, NETRA_APP.models.audioContext.currentTime + 0.1);
            oscillator.stop(NETRA_APP.models.audioContext.currentTime + 0.1);
        }
    };

    // --- Application Entry Point ---
    window.addEventListener('load', () => NETRA_APP.init());

    </script>
</body>
</html>

